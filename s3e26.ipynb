{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "j1J-CBrHVfJQ"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VnkTIm8aebST",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca7b1443-c948-4c5c-8bf2-2ced111bddf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.11.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.3)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.4)\n",
            "Requirement already satisfied: tensorflow_decision_forests in /usr/local/lib/python3.10/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.5.3)\n",
            "Requirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (2.15.0.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.16.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (1.4.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (0.42.0)\n",
            "Requirement already satisfied: wurlitzer in /usr/local/lib/python3.10/dist-packages (from tensorflow_decision_forests) (3.0.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (1.59.3)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tensorflow_decision_forests) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow_decision_forests) (2023.3.post1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow_decision_forests) (3.2.2)\n",
            "--2023-12-14 11:26:24--  https://raw.githubusercontent.com/h4pZ/rose-pine-matplotlib/main/themes/rose-pine-dawn.mplstyle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40905 (40K) [text/plain]\n",
            "Saving to: ‘/tmp/rose-pine-dawn.mplstyle’\n",
            "\n",
            "rose-pine-dawn.mpls 100%[===================>]  39.95K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-12-14 11:26:24 (12.7 MB/s) - ‘/tmp/rose-pine-dawn.mplstyle’ saved [40905/40905]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q scikit-lego\n",
        "!pip install catboost\n",
        "!pip install xgboost\n",
        "!pip install tensorflow_decision_forests\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from lightgbm import LGBMRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.ensemble import VotingRegressor\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor,RandomForestRegressor,BaggingRegressor\n",
        "\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import math\n",
        "import time\n",
        "import random\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "import missingno as msno\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.colors as mcolors\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "from sklearn.base import clone\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import KFold\n",
        "from scipy.spatial.distance import squareform\n",
        "from sklego.linear_model import LADRegression\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBRegressor, XGBClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from scipy.cluster.hierarchy import linkage, dendrogram\n",
        "from sklearn.ensemble import HistGradientBoostingRegressor, VotingRegressor\n",
        "from sklearn.metrics import median_absolute_error, roc_auc_score, roc_curve\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(style=\"whitegrid\")\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "!wget https://raw.githubusercontent.com/h4pZ/rose-pine-matplotlib/main/themes/rose-pine-dawn.mplstyle -P /tmp\n",
        "plt.style.use(\"/tmp/rose-pine-dawn.mplstyle\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/kaggle.json' ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c playground-series-s3e26\n",
        "!unzip playground-series-s3e26.zip"
      ],
      "metadata": {
        "id": "UYKWVM3SfrCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a5489be-586d-4130-d987-829134a03cd4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Downloading playground-series-s3e26.zip to /content\n",
            "  0% 0.00/350k [00:00<?, ?B/s]\n",
            "100% 350k/350k [00:00<00:00, 71.9MB/s]\n",
            "Archive:  playground-series-s3e26.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First approach"
      ],
      "metadata": {
        "id": "j1J-CBrHVfJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('train.csv').drop(columns=['id'],axis=1)\n",
        "test = pd.read_csv('test.csv').drop(\"id\",axis=1)\n",
        "sample_submisiion = pd.read_csv('sample_submission.csv')"
      ],
      "metadata": {
        "id": "jjeGrgkbvr1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_dataframe(df):\n",
        "    \"\"\"\n",
        "    Analyze a pandas DataFrame and provide a summary of its characteristics.\n",
        "\n",
        "    Parameters:\n",
        "    df (pandas.DataFrame): The input DataFrame to analyze.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    print(\"DataFrame Information:\")\n",
        "    print(\"----------------------\")\n",
        "    display(df.info(verbose=True, show_counts=True))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"DataFrame Values:\")\n",
        "    print(\"----------------------\")\n",
        "    display(df.head(5).T)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"DataFrame Description:\")\n",
        "    print(\"----------------------\")\n",
        "    display(df.describe().T)\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Number of Null Values:\")\n",
        "    print(\"----------------------\")\n",
        "    display(df.isnull().sum())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Number of Duplicated Rows:\")\n",
        "    print(\"--------------------------\")\n",
        "    display(df.duplicated().sum())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Number of Unique Values:\")\n",
        "    print(\"------------------------\")\n",
        "    display(df.nunique())\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"DataFrame Shape:\")\n",
        "    print(\"----------------\")\n",
        "    print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
        "\n",
        "# Usage\n",
        "analyze_dataframe(train)"
      ],
      "metadata": {
        "id": "C6rk8dBN-5tw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df.columns = ['id', 'N_Days', 'Status', 'Drug', 'Age', 'Sex', 'Ascites',\n",
        "       'Hepatomegaly', 'Spiders', 'Edema', 'Bilirubin', 'Cholesterol',\n",
        "       'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets',\n",
        "       'Prothrombin', 'Stage']\n",
        "\n",
        "set_frame_style(syn_df.head(),'Synthetically Generated Data\\n')\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "\n",
        "table = PrettyTable()\n",
        "table.field_names = [\"Features\",\"Unique Values\"]\n",
        "for i in list(syn_df.columns) :\n",
        "    nunique =syn_df[str(i)].nunique\n",
        "    table.add_row([i, f\"{nunique()}\"])\n",
        "print('Unique values in synthetically generated dataset : \\n')\n",
        "print(table)\n",
        "\n",
        "df = pd.concat([syn_df,original_df], axis =0)\n",
        "\n",
        "df = df.dropna()\n",
        "df = df.sample(frac = 1).reset_index(drop = True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "D9XD77ArBylS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_days_to_years(age_in_days):\n",
        "    days_in_year = 365.25\n",
        "    age_in_years = age_in_days / days_in_year\n",
        "    return age_in_years\n",
        "\n",
        "\n",
        "def add_cols(df):\n",
        "        age = list(df.Age)\n",
        "        age_in_year = []\n",
        "        for i in age :\n",
        "            age_in_year.append(int(convert_days_to_years(i)))\n",
        "        df['Age_in_year'] = pd.Series(age_in_year)\n",
        "        return df\n",
        "df = add_cols(df)\n",
        "original_df = add_cols(original_df)\n",
        "set_frame_style(df.head())\n",
        "\n",
        "threshold_platelets = 150\n",
        "df['thrombocytopenia'] = np.where(df['Platelets'] < threshold_platelets, 1, 0)\n",
        "test_df['thrombocytopenia'] = np.where(test_df['Platelets'] < threshold_platelets, 1, 0)\n",
        "\n",
        "threshold_alk_phos_upper = 147  # Upper limit of normal range\n",
        "threshold_alk_phos_lower = 44   # Lower limit of normal range\n",
        "\n",
        "df['elevated_alk_phos'] = np.where((df['Alk_Phos'] > threshold_alk_phos_upper) | (df['Alk_Phos'] < threshold_alk_phos_lower), 1, 0)\n",
        "test_df['elevated_alk_phos'] = np.where((test_df['Alk_Phos'] > threshold_alk_phos_upper) | (test_df['Alk_Phos'] < threshold_alk_phos_lower), 1, 0)\n",
        "\n",
        "normal_copper_range = (62, 140)\n",
        "\n",
        "df['normal_copper'] = np.where((df['Copper'] >= normal_copper_range[0]) & (df['Copper'] <= normal_copper_range[1]), 1, 0)\n",
        "test_df['normal_copper'] = np.where((test_df['Copper'] >= normal_copper_range[0]) & (test_df['Copper'] <= normal_copper_range[1]), 1, 0)\n",
        "\n",
        "normal_albumin_range = (3.4, 5.4)\n",
        "\n",
        "df['normal_albumin'] = np.where((df['Albumin'] >= normal_albumin_range[0]) & (df['Albumin'] <= normal_albumin_range[1]), 1, 0)\n",
        "\n",
        "test_df['normal_albumin'] = np.where((test_df['Albumin'] >= normal_albumin_range[0]) & (test_df['Albumin'] <= normal_albumin_range[1]), 1, 0)\n",
        "\n",
        "\n",
        "normal_bilirubin_range = (0.2, 1.2)\n",
        "\n",
        "df['normal_bilirubin'] = np.where((df['Bilirubin'] >= normal_bilirubin_range[0]) & (df['Bilirubin'] <= normal_bilirubin_range[1]), 1, 0)\n",
        "test_df['normal_bilirubin'] = np.where((test_df['Bilirubin'] >= normal_bilirubin_range[0]) & (test_df['Bilirubin'] <= normal_bilirubin_range[1]), 1, 0)"
      ],
      "metadata": {
        "id": "ynCCvoTehr4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_cols= ['N_Days',  'Age',  'Bilirubin', 'Cholesterol', 'Albumin', 'Copper',\n",
        "       'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n",
        "test_to_scale = test_df[numeric_cols]\n",
        "train_to_scale = df[numeric_cols]\n",
        "set_frame_style(train_to_scale.head(), 'Features with continuous values')\n",
        "train_to_scale_original = original_df[numeric_cols]"
      ],
      "metadata": {
        "id": "Njfjt6CbAVOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from plotly.subplots import make_subplots\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "columns = list(train_to_scale.columns)\n",
        "\n",
        "ultra_light_colors = [\n",
        "\"#F0F8FF\", \"#F6F6F6\", \"#F0FFF0\",  \"#FAFAD2\",  \"#FFE4E1\",  \"#FFF5EE\", \"#F5FFFA\",  \"#F0FFFF\",\"#FFFAF0\",  \"#F8F8FF\"\n",
        "]\n",
        "fig = make_subplots(rows=len(columns), cols=2)\n",
        "count = 0\n",
        "for row in range(int(len(columns))) :\n",
        "    random_col = f\"RGB({random.randint(100, 255)}, {random.randint(100, 255)}, {random.randint(150, 255)})\"\n",
        "    fig.add_trace(go.Violin(y=syn_df[numeric_cols][columns[count]], x0 = columns[count], box_visible=True, line_color='black',\n",
        "                               meanline_visible=True, fillcolor=random_col, opacity=0.6,), row=row + 1, col= 1)\n",
        "    fig.add_trace(go.Violin(y= train_to_scale_original[columns[count]],x0 = columns[count], box_visible=True, line_color='black',\n",
        "                               meanline_visible=True, fillcolor=random_col, opacity=0.6,), row=row + 1, col= 2)\n",
        "\n",
        "\n",
        "    count +=1\n",
        "\n",
        "\n",
        "fig.update_layout(height=2600, width=1000, title_text=\"Feature Distribution in Synthetic (Left) vs Original Dataset (Right)\",showlegend=False,paper_bgcolor= '#F5F5F5')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "A28M-eGBJjX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_frame_style(pd.DataFrame(df.Status.value_counts()), 'Data points per class', '15px')\n",
        "\n",
        "classes = list(df.Status.unique())\n",
        "\n",
        "ultra_light_colors = [\n",
        "\"#F0F8FF\", \"#F6F6F6\", \"#F0FFF0\",  \"#FAFAD2\",  \"#FFE4E1\",  \"#FFF5EE\", \"#F5FFFA\",  \"#F0FFFF\",\"#FFFAF0\",  \"#F8F8FF\"\n",
        "]\n",
        "def col_per_class(col):\n",
        "    fig = go.Figure()\n",
        "    for clas in classes :\n",
        "        fig.add_trace(go.Violin(y = df[col][df['Status']== clas],   box_visible=True,\n",
        "                            meanline_visible=True , x = df['Status'][df['Status'] == clas], name = clas ))\n",
        "        fig.update_layout(title = f'Distribution for {col} for each class', plot_bgcolor = ultra_light_colors[np.random.randint(1,10)],paper_bgcolor= '#F5F5F5', height=400,\n",
        "        width=1000 )\n",
        "    return fig\n",
        "for i in train_to_scale :\n",
        "    fig = col_per_class(i)\n",
        "    fig.show()"
      ],
      "metadata": {
        "id": "hehd_wSAEQpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "correlation_matrix = train_to_scale.corr()\n",
        "\n",
        "# Create a heatmap with masked upper triangle\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Blues', fmt='.2f', linewidths=.5)\n",
        "plt.title('Correlation Matrix (Lower Triangle)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JlfgRB8sEdSE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_frame_style(df.head())\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "sc = MinMaxScaler()\n",
        "\n",
        "\n",
        "scaled_train = pd.DataFrame(sc.fit_transform(train_to_scale),columns = train_to_scale.columns)\n",
        "scaled_test = pd.DataFrame(sc.transform(test_to_scale),columns = test_to_scale.columns)\n",
        "\n",
        "set_frame_style(scaled_train.head())"
      ],
      "metadata": {
        "id": "crxdHKr9EfTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ohe = df.drop(numeric_cols, axis =1)\n",
        "train_to_ohe = train_ohe.drop(['id','Age_in_year','Status'], axis =1)\n",
        "test_ohe = test_df.drop(numeric_cols, axis =1)\n",
        "test_to_ohe = test_ohe.drop(['id'],axis =1)\n",
        "set_frame_style(train_to_ohe.head())\n",
        "\n",
        "set_frame_style(test_to_ohe.head())"
      ],
      "metadata": {
        "id": "yr_1-7SjElMT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_train = pd.get_dummies(train_to_ohe, columns =train_to_ohe.columns )\n",
        "ohe_test  = pd.get_dummies(test_to_ohe, columns = train_to_ohe.columns)\n",
        "ohe_train = ohe_train.replace({True: 1, False: 0})\n",
        "ohe_test = ohe_test.replace({True: 1, False: 0})\n",
        "set_frame_style(ohe_train.head())"
      ],
      "metadata": {
        "id": "pc9K9B2eEofQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_1 = pd.concat([ohe_train, scaled_train], axis =1)\n",
        "test_df = pd.concat([ohe_test, scaled_test], axis =1)\n",
        "set_frame_style(train_df_1.head())"
      ],
      "metadata": {
        "id": "N2Xu1rupEqJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_1.info()\n",
        "\n",
        "train_df_1.shape"
      ],
      "metadata": {
        "id": "6jtEitDvErh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "X = train_df_1\n",
        "y = df['Status']\n",
        "\n",
        "# Label encode target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "\n",
        "\n",
        "# X, y_encoded = tomek_links(X, y_encoded)\n",
        "\n",
        "#XGBoost parameters\n",
        "xgb_params = {'max_depth': 6,\n",
        "          'min_child_weight': 10,\n",
        "          'learning_rate': 0.010009541152584345,\n",
        "          'n_estimators': 1878, 'subsample': 0.47524425009347593,\n",
        "          'colsample_bytree': 0.3292032860985591, 'random_state': 42,\n",
        "\n",
        "         'tree_method': 'hist',\n",
        "        'eval_metric': 'mlogloss',\n",
        "          'device' : 'cuda',\n",
        "        'verbosity': 2}\n",
        "\n",
        "# xgb_params = {'max_depth': 5,\n",
        "#  'min_child_weight': 8,\n",
        "#  'learning_rate': 0.10450346600896168,\n",
        "#  'n_estimators': 225,\n",
        "#  'subsample': 0.5855025206558809,\n",
        "#  'colsample_bytree': 0.14926372575849994,\n",
        "#  'reg_alpha': 0.7621405624015435,\n",
        "#  'reg_lambda': 0.6443164876665903,\n",
        "#          'tree_method': 'hist',\n",
        "#         'eval_metric': 'mlogloss',\n",
        "#           'device' : 'cuda',\n",
        "#         'verbosity': 2,\n",
        "#  'random_state': 42}\n",
        "\n",
        "# xgb_params ={'max_depth': 10,\n",
        "#          'min_child_weight': 7,\n",
        "#          'learning_rate': 0.03419253503641095,\n",
        "#          'n_estimators': 472,\n",
        "#          'subsample': 0.8843005833909504,\n",
        "#          'colsample_bytree': 0.0966352677605082,\n",
        "#          'random_state': 42,\n",
        "#          'tree_method': 'hist',\n",
        "#         'eval_metric': 'mlogloss',\n",
        "#           'device' : 'cuda',\n",
        "#         'verbosity': 2, }\n",
        "\n",
        "# xgb_params ={'max_depth': 8,\n",
        "#  'min_child_weight': 1,\n",
        "#  'learning_rate': 0.04242597466435193,\n",
        "#  'n_estimators': 686,\n",
        "#  'subsample': 0.5999261787239216,\n",
        "#  'colsample_bytree': 0.055073941529892194,\n",
        "#  'random_state': 42,\n",
        "# 'tree_method': 'hist',\n",
        "#         'eval_metric': 'mlogloss',\n",
        "#           'device' : 'cuda',\n",
        "#         'verbosity': 2,}\n",
        "\n",
        "# xgb_params = {\n",
        "#     'max_depth': 8,\n",
        "#     'min_child_weight': 6,\n",
        "#     'learning_rate': 0.013401933024622273,\n",
        "#     'n_estimators': 1472,\n",
        "#     'subsample': 0.281863681376234,\n",
        "#     'colsample_bytree': 0.15983733796975869,\n",
        "#     'random_state': 42,\n",
        "#     'tree_method': 'hist',\n",
        "#         'eval_metric': 'mlogloss',\n",
        "#           'device' : 'cuda',\n",
        "#         'verbosity': 2,\n",
        "# }\n",
        "\n",
        "# number of folds\n",
        "n_splits = 10\n",
        "\n",
        "#  StratifiedKFold\n",
        "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "#  cross-validation results\n",
        "cv_results = []\n",
        "\n",
        "# stratified k-fold cross-validation\n",
        "for fold, (train_idx, val_idx) in enumerate(stratkf.split(X, y_encoded)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "\n",
        "    # XGBoost model\n",
        "    xgb_model = XGBClassifier(**xgb_params )\n",
        "\n",
        "    xgb_model.fit(X_train, y_train )\n",
        "\n",
        "    # predictions on the validation set\n",
        "    y_val_pred_prob = xgb_model.predict_proba(X_val)\n",
        "\n",
        "    # Evaluating the model\n",
        "    logloss = log_loss(y_val, y_val_pred_prob)\n",
        "    print(f'Fold {fold + 1}, Logarithmic Loss on Validation Set: {logloss}')\n",
        "\n",
        "    # results\n",
        "    cv_results.append(logloss)\n",
        "\n",
        "# average cross-validation result\n",
        "average_cv_result = sum(cv_results) / n_splits\n",
        "print(f'\\nAverage Logarithmic Loss across {n_splits} folds: {average_cv_result}')\n"
      ],
      "metadata": {
        "id": "3A1gaotAExon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_names = train_df_1.columns\n",
        "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_feature_names, sorted_importance_scores = zip(*sorted_feature_importance)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.barh(sorted_feature_names, sorted_importance_scores)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Feature Name\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jbR6Ef_6EyMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb\n",
        "from sklearn.metrics import log_loss\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "# parameters\n",
        "# lgbm_params = {\n",
        "# 'n_estimators': 479,\n",
        "#  'learning_rate': 0.011780201673685327,\n",
        "#  'min_child_weight': 3.100349976889409,\n",
        "#  'subsample': 0.4975668919008305,\n",
        "#  'subsample_freq': 0,\n",
        "#  'colsample_bytree': 0.3960164652068705,\n",
        "#     'random_state': 42,\n",
        "#     'objective': 'multiclass',\n",
        "#     'num_class': 3,  # Number of classes in your target variable\n",
        "#     'metric': 'multi_logloss',\n",
        "#     'device': 'gpu',\n",
        "#     'verbosity': 0\n",
        "# }\n",
        "lgbm_params = {'objective': 'multi_logloss',\n",
        "               'max_depth': 9, 'min_child_samples': 14,\n",
        "               'learning_rate': 0.034869481921747415,\n",
        "               'n_estimators': 274, 'min_child_weight': 9,\n",
        "               'subsample': 0.7717873512945741,\n",
        "               'colsample_bytree': 0.1702910221565107,\n",
        "               'reg_alpha': 0.10626128775335533,\n",
        "               'reg_lambda': 0.624196407787772,\n",
        "               'random_state': 42,\n",
        "\n",
        "\n",
        "              }\n",
        "\n",
        "\n",
        "# folds\n",
        "n_splits = 10\n",
        "\n",
        "# StratifiedKFold\n",
        "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "cv_results = []\n",
        "\n",
        "\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(stratkf.split(X, y_encoded)):\n",
        "\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    lgbm_model = LGBMClassifier(**lgbm_params)\n",
        "    lgbm_model.fit(X_train,y_train)\n",
        "\n",
        "    y_val_pred_prob = lgbm_model.predict_proba(X_val)\n",
        "\n",
        "    logloss = log_loss(y_val, y_val_pred_prob)\n",
        "    print(f'Fold {fold + 1}, Logarithmic Loss on Validation Set: {logloss}')\n",
        "\n",
        "    cv_results.append(logloss)\n",
        "average_cv_result = sum(cv_results) / n_splits\n",
        "print(f'\\nAverage Logarithmic Loss across {n_splits} folds: {average_cv_result}')"
      ],
      "metadata": {
        "id": "jDZ4uoZSE4bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "catboost_params = {'iterations': 469,\n",
        "                   'depth': 20,\n",
        "                   'min_data_in_leaf': 11,\n",
        "                   'learning_rate': 0.13812945166006543,\n",
        "                   'grow_policy': 'Lossguide',\n",
        "                   'bootstrap_type' : 'Bernoulli'}\n",
        "\n",
        "n_splits = 10\n",
        "\n",
        "stratkf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "cv_results = []"
      ],
      "metadata": {
        "id": "crz2qA1YqeY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for fold, (train_idx, val_idx) in enumerate(stratkf.split(X, y_encoded)):\n",
        "    X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
        "\n",
        "    cat_model = CatBoostClassifier(**catboost_params,\n",
        "                            random_state=42, verbose =0\n",
        "                           )\n",
        "    cat_model.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "    y_val_pred_prob = cat_model.predict_proba(X_val)\n",
        "\n",
        "    logloss = log_loss(y_val, y_val_pred_prob)\n",
        "    print(f'Fold {fold + 1}, Logarithmic Loss on Validation Set: {logloss}')\n",
        "\n",
        "\n",
        "    cv_results.append(logloss)\n",
        "\n",
        "average_cv_result = sum(cv_results) / n_splits\n",
        "print(f'\\nAverage Logarithmic Loss across {n_splits} folds: {average_cv_result}')"
      ],
      "metadata": {
        "id": "ULhgh4XjE7UK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "\n",
        "# lgb_1 = LGBMClassifier(**lgbm_params )\n",
        "# xgb_1 = XGBClassifier(**xgb_params )\n",
        "# cb_1 = CatBoostClassifier(**catboost_params, random_state=42)\n",
        "Ensemble = VotingClassifier(estimators = [('lgb', lgbm_model), ('xgb', xgb_model), ('CB', cat_model)],\n",
        "                            voting='soft',\n",
        "                            weights = [0.45,0.5,0.05]   #Adjust weighting since XGB performs better in local environment\n",
        "                            )\n",
        "Ensemble.fit(X, y_encoded)"
      ],
      "metadata": {
        "id": "pJ_0O1BkE-Mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "feature_importances = xgb_model.feature_importances_\n",
        "feature_names = train_df_1.columns\n",
        "feature_importance_dict = dict(zip(feature_names, feature_importances))\n",
        "sorted_feature_importance = sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "sorted_feature_names, sorted_importance_scores = zip(*sorted_feature_importance)\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "plt.barh(sorted_feature_names, sorted_importance_scores)\n",
        "plt.xlabel(\"Feature Importance\")\n",
        "plt.ylabel(\"Feature Name\")\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.show()\n",
        "\n",
        "test_df.info()"
      ],
      "metadata": {
        "id": "B5AjeE7UFCgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = Ensemble.predict_proba(test_df)\n",
        "y_pred = pd.DataFrame(y_pred)\n",
        "y_pred.columns = ['Status_C', 'Status_CL','Status_D']\n",
        "y_pred.head()\n",
        "\n",
        "submission_df = pd.DataFrame()\n",
        "submission_df = y_pred\n",
        "submission_df['id'] = ids\n",
        "submission_df.head()\n",
        "\n",
        "submission_df.to_csv('submission.csv', index= False)"
      ],
      "metadata": {
        "id": "-BakJ8I0FGLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second approach"
      ],
      "metadata": {
        "id": "35mACr41VlSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.read_csv('sample_submission.csv')\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "train.info()"
      ],
      "metadata": {
        "id": "X4-WW6f4VnLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc00cb3e-2664-450b-c454-a7d25963b530"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7905 entries, 0 to 7904\n",
            "Data columns (total 20 columns):\n",
            " #   Column         Non-Null Count  Dtype  \n",
            "---  ------         --------------  -----  \n",
            " 0   id             7905 non-null   int64  \n",
            " 1   N_Days         7905 non-null   int64  \n",
            " 2   Drug           7905 non-null   object \n",
            " 3   Age            7905 non-null   int64  \n",
            " 4   Sex            7905 non-null   object \n",
            " 5   Ascites        7905 non-null   object \n",
            " 6   Hepatomegaly   7905 non-null   object \n",
            " 7   Spiders        7905 non-null   object \n",
            " 8   Edema          7905 non-null   object \n",
            " 9   Bilirubin      7905 non-null   float64\n",
            " 10  Cholesterol    7905 non-null   float64\n",
            " 11  Albumin        7905 non-null   float64\n",
            " 12  Copper         7905 non-null   float64\n",
            " 13  Alk_Phos       7905 non-null   float64\n",
            " 14  SGOT           7905 non-null   float64\n",
            " 15  Tryglicerides  7905 non-null   float64\n",
            " 16  Platelets      7905 non-null   float64\n",
            " 17  Prothrombin    7905 non-null   float64\n",
            " 18  Stage          7905 non-null   float64\n",
            " 19  Status         7905 non-null   object \n",
            "dtypes: float64(10), int64(3), object(7)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop('id', axis = 1)\n",
        "test = test.drop('id', axis = 1)\n",
        "\n",
        "print(train.isna().sum().any(),  test.isna().sum().any())\n",
        "\n",
        "total = pd.concat([train.drop('Status', axis=1), test], axis = 0)\n",
        "total.duplicated().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gIfW1jNFiJ9",
        "outputId": "621b0429-f807-458c-d9ec-49a84fb56181"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train[train.columns].nunique().sort_values(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3puu94QGBug",
        "outputId": "879ca782-b964-44fa-c929-ea0593849287"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Drug               2\n",
              "Sex                2\n",
              "Ascites            2\n",
              "Hepatomegaly       2\n",
              "Spiders            2\n",
              "Status             3\n",
              "Edema              3\n",
              "Stage              4\n",
              "Prothrombin       49\n",
              "Bilirubin        111\n",
              "Tryglicerides    154\n",
              "Albumin          160\n",
              "Copper           171\n",
              "SGOT             206\n",
              "Cholesterol      226\n",
              "Platelets        227\n",
              "Alk_Phos         364\n",
              "Age              391\n",
              "N_Days           461\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    }
  ]
}